{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of  TA_Live(Test)",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxpoiTP8hKBV",
        "outputId": "8014e666-0d5e-485d-aa0e-2068083e2c55"
      },
      "source": [
        "!pip install pandas-datareader\n",
        "!pip install --upgrade ta\n",
        "!pip install -U git+https://github.com/twopirllc/pandas-ta\n",
        "!pip install nest-asyncio\n",
        "!pip install -U git+https://github.com/mariostoev/finviz\n",
        "!pip install git+git://github.com/peerchemist/finta.git\n",
        "!pip install tiingo\n",
        " \n",
        "#!pip install pandas_ta\n",
        "#!pip install robin_stocks\n",
        "!pip install finviz\n",
        "!pip install PyPortfolioOpt\n",
        "#!pip install yfinance\n",
        "!pip install -U yfinance\n",
        " \n",
        " \n",
        "!pip install td-ameritrade-python-api==0.3.5\n",
        "!pip install selenium\n",
        "!pip install webdriver_manager\n",
        "!pip install fracdiff\n",
        " \n",
        "!pip install scikit-learn==0.23.\n",
        "!pip install portfoliolab\n",
        "!pip install --upgrade numpy\n",
        "!pip install pandas==1.3.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas-datareader in /usr/local/lib/python3.7/dist-packages (0.9.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from pandas-datareader) (4.6.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from pandas-datareader) (2.23.0)\n",
            "Requirement already satisfied: pandas>=0.23 in /usr/local/lib/python3.7/dist-packages (from pandas-datareader) (1.3.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23->pandas-datareader) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23->pandas-datareader) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23->pandas-datareader) (1.21.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.23->pandas-datareader) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader) (1.25.11)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader) (2021.5.30)\n",
            "Requirement already satisfied: ta in /usr/local/lib/python3.7/dist-packages (0.7.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from ta) (1.21.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from ta) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->ta) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->ta) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->ta) (1.15.0)\n",
            "Collecting git+https://github.com/twopirllc/pandas-ta\n",
            "  Cloning https://github.com/twopirllc/pandas-ta to /tmp/pip-req-build-4ph6zc_m\n",
            "  Running command git clone -q https://github.com/twopirllc/pandas-ta /tmp/pip-req-build-4ph6zc_m\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from pandas-ta==0.3.14b0) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas->pandas-ta==0.3.14b0) (1.21.3)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->pandas-ta==0.3.14b0) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->pandas-ta==0.3.14b0) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->pandas-ta==0.3.14b0) (1.15.0)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.7/dist-packages (1.5.1)\n",
            "Collecting git+https://github.com/mariostoev/finviz\n",
            "  Cloning https://github.com/mariostoev/finviz to /tmp/pip-req-build-mvguwmv6\n",
            "  Running command git clone -q https://github.com/mariostoev/finviz /tmp/pip-req-build-mvguwmv6\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting beautifulsoup4<5.0.0,>=4.9.3\n",
            "  Using cached beautifulsoup4-4.10.0-py3-none-any.whl (97 kB)\n",
            "Collecting tenacity<8.0.0,>=7.0.0\n",
            "  Using cached tenacity-7.0.0-py2.py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from finviz==1.4.2) (3.8.0)\n",
            "Requirement already satisfied: cssselect<2.0.0,>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from finviz==1.4.2) (1.1.0)\n",
            "Collecting urllib3<2.0.0,>=1.26.5\n",
            "  Using cached urllib3-1.26.7-py2.py3-none-any.whl (138 kB)\n",
            "Requirement already satisfied: lxml<5.0.0,>=4.6.3 in /usr/local/lib/python3.7/dist-packages (from finviz==1.4.2) (4.6.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.61.1 in /usr/local/lib/python3.7/dist-packages (from finviz==1.4.2) (4.62.3)\n",
            "Requirement already satisfied: user_agent<0.2.0,>=0.1.9 in /usr/local/lib/python3.7/dist-packages (from finviz==1.4.2) (0.1.9)\n",
            "Collecting requests<3.0.0,>=2.25.1\n",
            "  Using cached requests-2.26.0-py2.py3-none-any.whl (62 kB)\n",
            "\u001b[31mERROR: Package 'finviz' requires a different Python: 3.7.12 not in '<4.0,>=3.8'\u001b[0m\n",
            "Collecting git+git://github.com/peerchemist/finta.git\n",
            "  Cloning git://github.com/peerchemist/finta.git to /tmp/pip-req-build-05y2o709\n",
            "  Running command git clone -q git://github.com/peerchemist/finta.git /tmp/pip-req-build-05y2o709\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from finta==1.3) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from finta==1.3) (1.21.3)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->finta==1.3) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->finta==1.3) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->finta==1.3) (1.15.0)\n",
            "Requirement already satisfied: tiingo in /usr/local/lib/python3.7/dist-packages (0.14.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from tiingo) (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->tiingo) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->tiingo) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->tiingo) (1.25.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->tiingo) (2021.5.30)\n",
            "Requirement already satisfied: finviz in /usr/local/lib/python3.7/dist-packages (1.4.2)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from finviz) (1.25.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from finviz) (4.62.3)\n",
            "Requirement already satisfied: user-agent in /usr/local/lib/python3.7/dist-packages (from finviz) (0.1.9)\n",
            "Requirement already satisfied: tenacity in /usr/local/lib/python3.7/dist-packages (from finviz) (8.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from finviz) (2.23.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from finviz) (4.6.3)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from finviz) (3.8.0)\n",
            "Requirement already satisfied: cssselect in /usr/local/lib/python3.7/dist-packages (from finviz) (1.1.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from finviz) (4.6.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->finviz) (1.7.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->finviz) (21.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp->finviz) (3.7.4.3)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->finviz) (2.0.7)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->finviz) (4.0.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->finviz) (1.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->finviz) (1.2.0)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->finviz) (0.13.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->finviz) (5.2.0)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.7/dist-packages (from yarl<2.0,>=1.0->aiohttp->finviz) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->finviz) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->finviz) (2021.5.30)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from user-agent->finviz) (1.15.0)\n",
            "Requirement already satisfied: PyPortfolioOpt in /usr/local/lib/python3.7/dist-packages (1.5.1)\n",
            "Requirement already satisfied: scipy<2.0,>=1.3 in /usr/local/lib/python3.7/dist-packages (from PyPortfolioOpt) (1.7.1)\n",
            "Requirement already satisfied: cvxpy<2.0.0,>=1.1.10 in /usr/local/lib/python3.7/dist-packages (from PyPortfolioOpt) (1.1.15)\n",
            "Requirement already satisfied: pandas>=0.19 in /usr/local/lib/python3.7/dist-packages (from PyPortfolioOpt) (1.3.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from PyPortfolioOpt) (1.21.3)\n",
            "Requirement already satisfied: osqp>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from cvxpy<2.0.0,>=1.1.10->PyPortfolioOpt) (0.6.2.post0)\n",
            "Requirement already satisfied: scs>=1.1.6 in /usr/local/lib/python3.7/dist-packages (from cvxpy<2.0.0,>=1.1.10->PyPortfolioOpt) (2.1.4)\n",
            "Requirement already satisfied: ecos>=2 in /usr/local/lib/python3.7/dist-packages (from cvxpy<2.0.0,>=1.1.10->PyPortfolioOpt) (2.0.7.post1)\n",
            "Requirement already satisfied: qdldl in /usr/local/lib/python3.7/dist-packages (from osqp>=0.4.1->cvxpy<2.0.0,>=1.1.10->PyPortfolioOpt) (0.1.5.post0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.19->PyPortfolioOpt) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.19->PyPortfolioOpt) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.19->PyPortfolioOpt) (1.15.0)\n",
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.7/dist-packages (0.1.64)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.3.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.7/dist-packages (from yfinance) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.21.3)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from yfinance) (0.0.9)\n",
            "Requirement already satisfied: lxml>=4.5.1 in /usr/local/lib/python3.7/dist-packages (from yfinance) (4.6.3)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24->yfinance) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24->yfinance) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24->yfinance) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->yfinance) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->yfinance) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->yfinance) (1.25.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->yfinance) (2021.5.30)\n",
            "Requirement already satisfied: td-ameritrade-python-api==0.3.5 in /usr/local/lib/python3.7/dist-packages (0.3.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from td-ameritrade-python-api==0.3.5) (2.23.0)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.7/dist-packages (from td-ameritrade-python-api==0.3.5) (1.1.4)\n",
            "Requirement already satisfied: pyopenssl in /usr/local/lib/python3.7/dist-packages (from td-ameritrade-python-api==0.3.5) (21.0.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.7/dist-packages (from td-ameritrade-python-api==0.3.5) (1.3.0)\n",
            "Requirement already satisfied: websockets in /usr/local/lib/python3.7/dist-packages (from td-ameritrade-python-api==0.3.5) (10.0)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from flask->td-ameritrade-python-api==0.3.5) (1.1.0)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from flask->td-ameritrade-python-api==0.3.5) (1.0.1)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from flask->td-ameritrade-python-api==0.3.5) (7.1.2)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from flask->td-ameritrade-python-api==0.3.5) (2.11.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->flask->td-ameritrade-python-api==0.3.5) (2.0.1)\n",
            "Requirement already satisfied: cryptography>=3.3 in /usr/local/lib/python3.7/dist-packages (from pyopenssl->td-ameritrade-python-api==0.3.5) (35.0.0)\n",
            "Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from pyopenssl->td-ameritrade-python-api==0.3.5) (1.15.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=3.3->pyopenssl->td-ameritrade-python-api==0.3.5) (1.14.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=3.3->pyopenssl->td-ameritrade-python-api==0.3.5) (2.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->td-ameritrade-python-api==0.3.5) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->td-ameritrade-python-api==0.3.5) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->td-ameritrade-python-api==0.3.5) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->td-ameritrade-python-api==0.3.5) (1.25.11)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib->td-ameritrade-python-api==0.3.5) (3.1.1)\n",
            "Requirement already satisfied: selenium in /usr/local/lib/python3.7/dist-packages (4.0.0)\n",
            "Requirement already satisfied: trio-websocket~=0.9 in /usr/local/lib/python3.7/dist-packages (from selenium) (0.9.2)\n",
            "Collecting urllib3[secure]~=1.26\n",
            "  Using cached urllib3-1.26.7-py2.py3-none-any.whl (138 kB)\n",
            "Requirement already satisfied: trio~=0.17 in /usr/local/lib/python3.7/dist-packages (from selenium) (0.19.0)\n",
            "Requirement already satisfied: outcome in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (1.1.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (1.2.0)\n",
            "Requirement already satisfied: async-generator>=1.9 in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (1.10)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (2.10)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (21.2.0)\n",
            "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.7/dist-packages (from trio-websocket~=0.9->selenium) (1.0.0)\n",
            "Requirement already satisfied: cryptography>=1.3.4 in /usr/local/lib/python3.7/dist-packages (from urllib3[secure]~=1.26->selenium) (35.0.0)\n",
            "Requirement already satisfied: pyOpenSSL>=0.14 in /usr/local/lib/python3.7/dist-packages (from urllib3[secure]~=1.26->selenium) (21.0.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from urllib3[secure]~=1.26->selenium) (2021.5.30)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=1.3.4->urllib3[secure]~=1.26->selenium) (1.14.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=1.3.4->urllib3[secure]~=1.26->selenium) (2.20)\n",
            "Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from pyOpenSSL>=0.14->urllib3[secure]~=1.26->selenium) (1.15.0)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.12.0)\n",
            "Installing collected packages: urllib3\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.25.11\n",
            "    Uninstalling urllib3-1.25.11:\n",
            "      Successfully uninstalled urllib3-1.25.11\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "requests 2.23.0 requires urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1, but you have urllib3 1.26.7 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas~=1.1.0; python_version >= \"3.0\", but you have pandas 1.3.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed urllib3-1.26.7\n",
            "Requirement already satisfied: webdriver_manager in /usr/local/lib/python3.7/dist-packages (3.5.1)\n",
            "Requirement already satisfied: configparser in /usr/local/lib/python3.7/dist-packages (from webdriver_manager) (5.0.2)\n",
            "Requirement already satisfied: crayons in /usr/local/lib/python3.7/dist-packages (from webdriver_manager) (0.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from webdriver_manager) (2.23.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (from crayons->webdriver_manager) (0.4.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->webdriver_manager) (2021.5.30)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Using cached urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->webdriver_manager) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->webdriver_manager) (2.10)\n",
            "Installing collected packages: urllib3\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.26.7\n",
            "    Uninstalling urllib3-1.26.7:\n",
            "      Successfully uninstalled urllib3-1.26.7\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "selenium 4.0.0 requires urllib3[secure]~=1.26, but you have urllib3 1.25.11 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas~=1.1.0; python_version >= \"3.0\", but you have pandas 1.3.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed urllib3-1.25.11\n",
            "Requirement already satisfied: fracdiff in /usr/local/lib/python3.7/dist-packages (0.7.0)\n",
            "Collecting scikit-learn<2.0.0,>=1.0.1\n",
            "  Using cached scikit_learn-1.0.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (23.2 MB)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.21.3 in /usr/local/lib/python3.7/dist-packages (from fracdiff) (1.21.3)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.7.1 in /usr/local/lib/python3.7/dist-packages (from fracdiff) (1.7.1)\n",
            "Requirement already satisfied: statsmodels<0.14.0,>=0.13.0 in /usr/local/lib/python3.7/dist-packages (from fracdiff) (0.13.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<2.0.0,>=1.0.1->fracdiff) (1.0.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<2.0.0,>=1.0.1->fracdiff) (3.0.0)\n",
            "Requirement already satisfied: pandas>=0.25 in /usr/local/lib/python3.7/dist-packages (from statsmodels<0.14.0,>=0.13.0->fracdiff) (1.3.0)\n",
            "Requirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.7/dist-packages (from statsmodels<0.14.0,>=0.13.0->fracdiff) (0.5.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25->statsmodels<0.14.0,>=0.13.0->fracdiff) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25->statsmodels<0.14.0,>=0.13.0->fracdiff) (2.8.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from patsy>=0.5.2->statsmodels<0.14.0,>=0.13.0->fracdiff) (1.15.0)\n",
            "Installing collected packages: scikit-learn\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 0.23.0\n",
            "    Uninstalling scikit-learn-0.23.0:\n",
            "      Successfully uninstalled scikit-learn-0.23.0\n",
            "Successfully installed scikit-learn-1.0.1\n",
            "Collecting scikit-learn==0.23.\n",
            "  Using cached scikit_learn-0.23.0-cp37-cp37m-manylinux1_x86_64.whl (7.3 MB)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.23.) (1.21.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.23.) (1.0.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.23.) (3.0.0)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.23.) (1.7.1)\n",
            "Installing collected packages: scikit-learn\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.0.1\n",
            "    Uninstalling scikit-learn-1.0.1:\n",
            "      Successfully uninstalled scikit-learn-1.0.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "fracdiff 0.7.0 requires scikit-learn<2.0.0,>=1.0.1, but you have scikit-learn 0.23.0 which is incompatible.\u001b[0m\n",
            "Successfully installed scikit-learn-0.23.0\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement portfoliolab (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for portfoliolab\u001b[0m\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.21.3)\n",
            "Requirement already satisfied: pandas==1.3.0 in /usr/local/lib/python3.7/dist-packages (1.3.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.3.0) (2018.9)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.3.0) (1.21.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.3.0) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas==1.3.0) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1G6ecJa2uFy"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas_datareader.data as pdr\n",
        "import ta\n",
        "import pandas_ta \n",
        "from pandas import DataFrame, Series\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "import finviz\n",
        "from finviz.screener import Screener\n",
        "from finta import TA\n",
        "import tiingo\n",
        "from tiingo import TiingoClient\n",
        "import requests\n",
        " \n",
        "from statistics import mean,median\n",
        "import urllib\n",
        "from urllib.parse import urlencode, quote_plus\n",
        "import pypfopt\n",
        "from pypfopt import objective_functions\n",
        " \n",
        "from google.colab import files\n",
        "import csv\n",
        "from collections import OrderedDict\n",
        "import json\n",
        " \n",
        "#import robin_stocks as rs\n",
        "from dateutil import parser\n",
        "import scipy\n",
        "from scipy import stats as scipy_stats\n",
        " \n",
        " \n",
        "import yfinance as yf\n",
        "yf.pdr_override()\n",
        " \n",
        "import td\n",
        "from td.client import TDClient\n",
        " \n",
        "import requests\n",
        "import datetime as dt\n",
        "from statistics import mean,median\n",
        "import urllib\n",
        "from urllib.parse import urlencode, quote_plus\n",
        " \n",
        "import selenium\n",
        "from selenium import webdriver\n",
        "from webdriver_manager.opera import OperaDriverManager\n",
        "import json\n",
        "from fracdiff import FracdiffStat\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        " \n",
        "import sklearn\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wl3ULrtCnfct"
      },
      "source": [
        "import cython\n",
        "%load_ext cython"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQVk86VlKNWl"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas_datareader.data as pdr\n",
        "import ta\n",
        "import pandas_ta \n",
        "from pandas import DataFrame, Series\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "import finviz\n",
        "from finviz.screener import Screener\n",
        "from finta import TA\n",
        "import tiingo\n",
        "from tiingo import TiingoClient\n",
        "import requests\n",
        " \n",
        "from statistics import mean,median\n",
        "import urllib\n",
        "from urllib.parse import urlencode, quote_plus\n",
        "import pypfopt\n",
        "from pypfopt import objective_functions\n",
        " \n",
        "from google.colab import files\n",
        "import csv\n",
        "from collections import OrderedDict\n",
        "import json\n",
        " \n",
        "#import robin_stocks as rs\n",
        "from dateutil import parser\n",
        "import scipy\n",
        "from scipy import stats as scipy_stats\n",
        " \n",
        " \n",
        "import yfinance as yf\n",
        "yf.pdr_override()\n",
        " \n",
        "import td\n",
        "from td.client import TDClient\n",
        " \n",
        "import requests\n",
        "import datetime as dt\n",
        "from statistics import mean,median\n",
        "import urllib\n",
        "from urllib.parse import urlencode, quote_plus\n",
        " \n",
        "import selenium\n",
        "from selenium import webdriver\n",
        "from webdriver_manager.opera import OperaDriverManager\n",
        "import json\n",
        "from fracdiff import FracdiffStat\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        " \n",
        "import sklearn\n",
        " \n",
        " \n",
        "import warnings\n",
        "warnings.simplefilter(\"ignore\")\n",
        " \n",
        "def yahooTA(ticker,freq):\n",
        "  \n",
        "  sixty=['1m','2m','5m','15m','30m','15m']\n",
        " \n",
        "  if freq in sixty:\n",
        "    data=pdr.get_data_yahoo(ticker,interval=freq,period='60d')\n",
        "    data.index=data.index.tz_convert('US/Pacific')\n",
        "  \n",
        "  elif freq=='1h':\n",
        "    data=pdr.get_data_yahoo(ticker,interval=freq,period='710d')\n",
        "    data.index=data.index.tz_convert('US/Pacific')\n",
        "  \n",
        "  elif freq=='1d' or freq=='1wk':\n",
        "    #data=pdr.get_data_yahoo(ticker,interval=freq)\n",
        "    data=pdr.get_data_yahoo(ticker,interval=freq,period='360d')\n",
        "  \n",
        "  elif freq=='1mo':\n",
        "    data=pdr.get_data_yahoo(ticker,interval=freq,period='1200d')\n",
        "   \n",
        "  data=data.drop('Adj Close',axis=1)\n",
        "  #data=data.reset_index()\n",
        "  \n",
        "  data['mfi2']=ta.volume.money_flow_index(high=data['High'],low=data['Low'],close=data['Close'],volume=data['Volume'],window=2)\n",
        "  data['mfi10']=ta.volume.money_flow_index(high=data['High'],low=data['Low'],close=data['Close'],volume=data['Volume'],window=10)\n",
        "  \n",
        "  data['rsi10']=ta.momentum.rsi(close=data['Close'],window=10)\n",
        "  data['rsi2']=ta.momentum.rsi(close=data['Close'],window=2)            \n",
        " \n",
        "  data['hma10']=pandas_ta.hma(data['Close'],length=10)\n",
        "  data['hma20']=pandas_ta.hma(data['Close'],length=20)\n",
        "  data['hma50']=pandas_ta.hma(data['Close'],length=50)\n",
        "  #data['hma150']=pandas_ta.hma(data['Close'],length=150)\n",
        "  #data['ema200']=ta.trend.ema_indicator(data['Close'],window=200)\n",
        "  data['ema10']=pandas_ta.ema(data['Close'],length=10)\n",
        "  data['ema20']=pandas_ta.ema(data['Close'],length=20)\n",
        "  data['ema50']=pandas_ta.ema(data['Close'],length=50)\n",
        " \n",
        "  #data['natr']=pandas_ta.natr(data['High'],data['Low'],data['Close'],length=10)\n",
        " \n",
        "  psar=pandas_ta.psar(data['High'],data['Low'],data['Close'],0.4,0.4,0.4)\n",
        "    \n",
        "  psar['PSARl_0.4_0.4'].fillna(psar['PSARs_0.4_0.4'],inplace=True)\n",
        "  data['psar']=psar['PSARl_0.4_0.4']\n",
        " \n",
        "  psar=pandas_ta.psar(data['High'],data['Low'],data['Close'],2,2,2)\n",
        " \n",
        "  psar['PSARl_2.0_2.0'].fillna(psar['PSARs_2.0_2.0'],inplace=True)\n",
        "  data['stop_loss']=psar['PSARl_2.0_2.0']\n",
        " \n",
        "  data['hbb']=ta.volatility.bollinger_hband(data['Close'])\n",
        "  data['lbb']=ta.volatility.bollinger_lband(data['Close'])\n",
        "     \n",
        "  data['close_returns']=data.Close.pct_change(periods=1)\n",
        "  data['price_roc']=data.Close.diff()\n",
        "  data['vol_roc']=data.Volume.diff().ewm(span=10).mean()\n",
        " \n",
        "  data['Volume'].iloc[:data['hma10'].isnull().sum()]=data['hma10'].iloc[:data['hma10'].isnull().sum()]\n",
        " \n",
        "  data['vol_ema']=data['Volume'].ewm(span=10).mean()\n",
        "  \n",
        "  try:\n",
        "    keltner=pandas_ta.kc(data['High'],data['Low'],data['Close'],scale=1.5,mamode='ema')\n",
        "    keltner.columns=['lkeltner','mkeltner','hkeltner']\n",
        "  \n",
        "  except:\n",
        "    keltner=pandas_ta.kc(data['High'],data['Low'],data['Close'],scale=1.5,mamode='ema',length=12)\n",
        "    keltner.columns=['lkeltner','mkeltner','hkeltner']\n",
        "    pass\n",
        " \n",
        "  data=pd.concat([data,keltner],axis=1)\n",
        "  \n",
        "  data.columns=[col.lower() for col in data.columns]\n",
        " \n",
        "  data['cci10']=pandas_ta.cci(data['low'],data['high'],data['close'],length=10)\n",
        "  data['cci2']=pandas_ta.cci(data['low'],data['high'],data['close'],length=2)\n",
        " \n",
        "  #data['qstick10']=pandas_ta.qstick(data['open'],data['close'],length=10)\n",
        "  #data['qstick2']=pandas_ta.qstick(data['open'],data['close'],length=2)\n",
        " \n",
        "  #data['kvo']=pandas_ta.kvo(data['high'],data['low'],data['close'],data['volume'],fast=20,long=50,length_sig=10)['KVOs_20_55_13']\n",
        "  #data['eri']=pandas_ta.eri(data['high'],data['low'],data['close'],length=10)\n",
        "  \n",
        "  return data\n",
        " \n",
        "def Prices(stocks_list,freq):\n",
        " \n",
        "  prices_df=pd.DataFrame()\n",
        "  sixty=['1m','2m','5m','30m','15m']\n",
        "  \n",
        "  for ticker in stocks_list:\n",
        "    \n",
        "    if freq in sixty:\n",
        "      data=pdr.get_data_yahoo(ticker,interval=freq,period='60d')\n",
        "      data.index=data.index.tz_convert('US/Pacific')\n",
        "    \n",
        "    elif freq=='1h':\n",
        "      data=pdr.get_data_yahoo(ticker,interval=freq,period='710d')\n",
        "      data.index=data.index.tz_convert('US/Pacific')\n",
        "    \n",
        "    else:\n",
        "      data=pdr.get_data_yahoo(ticker,interval=freq)\n",
        "      \n",
        "    prices_df[str(ticker)]=data['Close']\n",
        "      \n",
        "      #prices_df=prices_df.dropna(axis=0)\n",
        " \n",
        "  return prices_df\n",
        " \n",
        "def Last_Prices(ticker_list,freq):\n",
        "  sixty=['1m','2m','5m','30m','15m']\n",
        "  price_series=pd.Series()\n",
        " \n",
        "  for ticker in ticker_list:\n",
        "    \n",
        "    if freq in sixty:\n",
        "      data=pdr.get_data_yahoo(ticker,interval=freq,period='60d')\n",
        "      data.index=data.index.tz_convert('US/Pacific')\n",
        "    \n",
        "    elif freq=='1h':\n",
        "      data=pdr.get_data_yahoo(ticker,interval=freq,period='710d')\n",
        "      data.index=data.index.tz_convert('US/Pacific')\n",
        "    \n",
        "    else:\n",
        "      data=pdr.get_data_yahoo(ticker,interval=freq)\n",
        "  \n",
        "    price_series[ticker]=data.Close.iloc[-1]\n",
        " \n",
        "  return price_series\n",
        " \n",
        "def yf_fetch(ticker_list):\n",
        " \n",
        "  returns_df=pd.DataFrame()\n",
        "  prices_df=pd.DataFrame()\n",
        " \n",
        "  for ticker in ticker_list:\n",
        "    data=yf.Ticker(ticker).history(period='max')\n",
        "   \n",
        "    data['returns']=data.Close.pct_change()\n",
        " \n",
        "    returns_df[str(ticker)]=data['returns']\n",
        "    prices_df[str(ticker)]=data['Close']\n",
        "  \n",
        "  return returns_df,prices_df\n",
        " \n",
        "def yf_intraday(ticker_list):\n",
        "  returns_df=pd.DataFrame()\n",
        "  prices_df=pd.DataFrame()\n",
        " \n",
        "  for ticker in ticker_list:\n",
        "    data=yf.Ticker(ticker).history(period='60d',interval='15m')\n",
        "    data['returns']=data.Close.pct_change()\n",
        " \n",
        "    returns_df[str(ticker)]=data['returns']\n",
        "    prices_df[str(ticker)]=data['Close']\n",
        " \n",
        "  return returns_df,prices_df\n",
        " \n",
        "def Returns(stocks_list):\n",
        " \n",
        "  returns_df=pd.DataFrame()\n",
        "  \n",
        "  for stock_symbol in stocks_list:\n",
        "     \n",
        "    data=pdr.get_data_yahoo(stock_symbol.replace('.',''))\n",
        "    \n",
        "    returns_df[str(stock_symbol)]=data['Close'].pct_change()\n",
        "    \n",
        "    #prices_df=prices_df.dropna(axis=0)\n",
        " \n",
        "  return returns_df\n",
        " \n",
        "def Blacklitter(prices_df,view_dict):\n",
        "  risk_model=pypfopt.risk_models.CovarianceShrinkage(prices_df)\n",
        "  cov_matrix=risk_model.oracle_approximating()\n",
        " \n",
        "  view_series=pd.Series(view_dict)\n",
        " \n",
        "  #cov_matrix=pypfopt.risk_models.fix_nonpositive_semidefinite(cov_matrix,fix_method='spectral')\n",
        " \n",
        "  #if np.linalg.det(cov_matrix)==0:\n",
        "    #cov_matrix=cov_matrix+0.0000001\n",
        "  \n",
        "  bl=pypfopt.black_litterman.BlackLittermanModel(cov_matrix=cov_matrix,absolute_views=view_series)\n",
        " \n",
        "  weights=bl.bl_weights()\n",
        "  weights=bl.clean_weights(cutoff=0.000001,rounding=8)\n",
        " \n",
        "  return dict(weights)\n",
        " \n",
        "def Blacklitter2(prices_df,views_dict,method):\n",
        "  view_series=pd.Series(views_dict)\n",
        "  view_series=view_series[view_series!=0]\n",
        "  hrp_weights=HR_Paritize(prices_df,views_dict,method)\n",
        "  hrp_series=pd.Series(hrp_weights) \n",
        " \n",
        "  risk_model=pypfopt.risk_models.CovarianceShrinkage(prices_df)\n",
        "  cov_matrix=risk_model.oracle_approximating()\n",
        " \n",
        "  repeat=np.array(hrp_series-1/len(hrp_series))\n",
        "  P=np.vstack([repeat]*len(view_series))\n",
        "  Q=np.array(view_series).reshape(-1,1)\n",
        " \n",
        "  bl=pypfopt.black_litterman.BlackLittermanModel(cov_matrix=cov_matrix,Q=Q,P=P)\n",
        "  weights=bl.bl_weights()\n",
        "  weights=bl.clean_weights(cutoff=0.000001,rounding=8)\n",
        " \n",
        "  if np.isinf(pd.Series(weights)).sum()==len(weights):\n",
        "    one_df=pd.Series([1 if x>0 else -1 for x in pd.Series(weights)],index=weights.keys())\n",
        "    \n",
        "    one_df=one_df/(abs(one_df)).sum()\n",
        "    weights=dict(one_df)\n",
        " \n",
        "  return dict(weights)\n",
        " \n",
        "def HR_Paritize(prices_df,views_dict,method='median'):\n",
        " \n",
        "  if len(views_dict)==1:\n",
        "    return {x:1 for x in views_dict}\n",
        "  \n",
        "  elif len(views_dict)==0:\n",
        "    return {}\n",
        "  \n",
        "  else:\n",
        "    \n",
        "    views_df=pd.Series(views_dict)\n",
        " \n",
        "    prices_df=prices_df[views_df.index]\n",
        " \n",
        "    risk_model=pypfopt.risk_models.CovarianceShrinkage(prices_df)\n",
        "    cov_matrix=risk_model.oracle_approximating()\n",
        " \n",
        "    hrp=pypfopt.hierarchical_portfolio.HRPOpt(cov_matrix=cov_matrix)\n",
        " \n",
        "    abs_weights=dict(hrp.optimize(method))\n",
        "    \n",
        "    return abs_weights\n",
        " \n",
        "def norm(x):\n",
        "    \n",
        "    nom = (x - x.min())*1.33\n",
        "    denom = x.max() - x.min()\n",
        "    return  nom/denom\n",
        " \n",
        "def tanm(x):\n",
        "  e=2.71828\n",
        "  numerator=(e**(15*x)-e**(7.5))\n",
        "  denominator=(e**(15*x)+e**(7.5))**-1\n",
        " \n",
        "  if isinstance(x,float)==True:\n",
        "    if np.isnan(numerator * denominator)==True:\n",
        "      return 1\n",
        "    \n",
        "    else:\n",
        "      return numerator*denominator\n",
        "    \n",
        "  else:\n",
        "    return numerator*denominator\n",
        " \n",
        "def as_currency(amount):\n",
        "  \n",
        "    if amount >= 0:\n",
        "        return float('{:.2f}'.format(amount))\n",
        "    else:\n",
        "        return float('-{:.2f}'.format(-amount))\n",
        " \n",
        "def single_trail(ticker,size,TDSession,account_id,stop_loss,short=False):\n",
        " \n",
        "    if short:\n",
        "      instruction='BUY_TO_COVER'\n",
        "    \n",
        "    else:\n",
        "      instruction='SELL'\n",
        " \n",
        "    order={\n",
        "        \"orderType\": \"TRAILING_STOP\",\n",
        "        \"stopPriceOffset\": stop_loss,\n",
        "        \"stopPriceLinkType\": \"VALUE\",\n",
        "        \"stopPriceLinkBasis\": \"ASK\",\n",
        "        \"stopType\": \"STANDARD\",\n",
        "        \"session\": \"NORMAL\",\n",
        "        \"duration\": \"GOOD_TILL_CANCEL\",\n",
        "        \"orderStrategyType\": \"SINGLE\",\n",
        "        \"orderLegCollection\": [\n",
        "          {\n",
        "            \"instruction\": instruction,\n",
        "            \"quantity\": size,\n",
        "            \"instrument\": {\n",
        "              \"symbol\": ticker,\n",
        "              \"assetType\": \"EQUITY\"\n",
        "            }\n",
        "          }]}\n",
        "    \n",
        "    TDSession.place_order(account_id,order)\n",
        " \n",
        "def single_stop(ticker,size,stop_price):\n",
        "    \n",
        "    stop_market={\n",
        "    \"orderType\": \"STOP\",\n",
        "    \"session\": 'NORMAL',\n",
        "    \"duration\": \"GOOD_TILL_CANCEL\",\n",
        "    \"stopPrice\": stop_price,\n",
        "    \"orderStrategyType\": \"SINGLE\",\n",
        "    \"orderLegCollection\": [\n",
        "      {\n",
        "        \"instruction\": \"SELL\",\n",
        "        \"quantity\": size,\n",
        "        \"instrument\": {\n",
        "          \"symbol\": ticker,\n",
        "          \"assetType\": \"EQUITY\"\n",
        "        }\n",
        "      }\n",
        "    ]\n",
        "  }\n",
        "    return stop_market\n",
        " \n",
        "def buy_anytime(ticker,size,TDSession,account_id,short=False):\n",
        "    \n",
        "    ticker=ticker.upper()\n",
        "    size=abs(size)\n",
        "    quote=TDSession.get_quotes(instruments=[ticker])\n",
        "    \n",
        "      \n",
        "    if short:\n",
        "      instruction='SELL_SHORT'\n",
        "      price=quote[ticker]['bidPrice']-0.01\n",
        "    \n",
        "    else:\n",
        "       instruction='BUY'\n",
        "       price=quote[ticker]['askPrice']+0.01\n",
        "    \n",
        "    price=as_currency(price)\n",
        " \n",
        "    order={\n",
        "    \"orderType\": \"LIMIT\",\n",
        "    \"session\": 'SEAMLESS',\n",
        "    \"duration\": \"DAY\",\n",
        "    \"price\": price,\n",
        "    \"orderStrategyType\": \"SINGLE\",\n",
        "    \"orderLegCollection\": [\n",
        "      {\n",
        "        \"instruction\": instruction,\n",
        "        \"quantity\": size,\n",
        "        \"instrument\": {\n",
        "          \"symbol\": ticker,\n",
        "          \"assetType\": \"EQUITY\"\n",
        "        }\n",
        "      }\n",
        "    ]\n",
        "  }\n",
        "    TDSession.place_order(account_id,order)\n",
        " \n",
        "def sell_anytime(ticker,size,TDSession,account_id,short=False):\n",
        "    \n",
        "    ticker=ticker.upper()\n",
        "    size=abs(size)\n",
        "    quote=TDSession.get_quotes(instruments=[ticker])\n",
        "      \n",
        "    if short:\n",
        "      instruction='BUY_TO_COVER'\n",
        "      price=quote[ticker]['askPrice']+0.01\n",
        "    \n",
        "    else:\n",
        "       instruction='SELL'\n",
        "       price=quote[ticker]['bidPrice']-0.01\n",
        "    \n",
        "    price=as_currency(price)\n",
        "    \n",
        "    order={\n",
        "    \"orderType\": \"LIMIT\",\n",
        "    \"session\": 'SEAMLESS',\n",
        "    \"duration\": \"DAY\",\n",
        "    \"price\": price,\n",
        "    \"orderStrategyType\": \"SINGLE\",\n",
        "    \"orderLegCollection\": [\n",
        "      {\n",
        "        \"instruction\": instruction,\n",
        "        \"quantity\": size,\n",
        "        \"instrument\": {\n",
        "          \"symbol\": ticker,\n",
        "          \"assetType\": \"EQUITY\"\n",
        "        }\n",
        "      }\n",
        "    ]\n",
        "  }\n",
        "     \n",
        "    TDSession.place_order(account_id,order)\n",
        " \n",
        "def market_order(ticker,size,TDSession,account_id,sell=False,short=False):\n",
        "  size=abs(size)\n",
        "  ticker=ticker.upper()\n",
        "    \n",
        "  if short and sell:\n",
        "    instruction='BUY_TO_COVER'\n",
        "  \n",
        "  elif short and not sell:\n",
        "    instruction='SELL_SHORT'\n",
        "  \n",
        "  elif sell and not short:\n",
        "    instruction='SELL'\n",
        " \n",
        "  else:\n",
        "    instruction='BUY'\n",
        "      \n",
        "  order={\n",
        "  \"orderType\": \"MARKET\",\n",
        "  \"session\": 'NORMAL',\n",
        "  \"duration\": \"DAY\",\n",
        "  \"orderStrategyType\": \"SINGLE\",\n",
        "  \"orderLegCollection\": [\n",
        "    {\n",
        "      \"instruction\": instruction,\n",
        "      \"quantity\": size,\n",
        "      \"instrument\": {\n",
        "        \"symbol\": ticker,\n",
        "        \"assetType\": \"EQUITY\"\n",
        "      }\n",
        "    }\n",
        "  ]\n",
        "}\n",
        " \n",
        "  TDSession.place_order(account_id,order)\n",
        " \n",
        "def stop_market(ticker,size,stop_price,TDSession,account_id,sell=False,short=False):\n",
        "  size=abs(size)\n",
        "  ticker=ticker.upper()\n",
        "  \n",
        "  if short and sell:\n",
        "    instruction='BUY_TO_COVER'\n",
        "  \n",
        "  elif short and not sell:\n",
        "    instruction='SELL_SHORT'\n",
        "  \n",
        "  elif sell and not short:\n",
        "    instruction='SELL'\n",
        " \n",
        "  else:\n",
        "    instruction='BUY'\n",
        " \n",
        "  order={\n",
        " \n",
        "    \"orderType\": \"STOP\",\n",
        "    \"session\": \"NORMAL\",\n",
        "    \"duration\": \"DAY\",\n",
        "    \"stopPrice\": stop_price,\n",
        "    \"orderStrategyType\": \"SINGLE\",\n",
        "    \"orderLegCollection\": [\n",
        "      {\n",
        "        \"instruction\": instruction,\n",
        "        \"quantity\": size,\n",
        "        \"instrument\": {\n",
        "          \"symbol\": ticker,\n",
        "          \"assetType\": \"EQUITY\"\n",
        "        }\n",
        "      }\n",
        "    ]\n",
        "  }\n",
        "  \n",
        "  TDSession.place_order(account_id,order)\n",
        "  \n",
        " \n",
        "def conditional_order(ticker,size,stop_size,stop_price,TDSession,account_id,short=False,sell=False):\n",
        "  \n",
        "  size=abs(size)\n",
        "  stop_size=abs(stop_size)\n",
        "  ticker=ticker.upper()\n",
        " \n",
        "  if not (short and sell):\n",
        "    bid=TDSession.get_quotes([ticker])[ticker.upper()]['bidPrice']\n",
        "    instruction='BUY'\n",
        "    stop_instruction='SELL'\n",
        "    stop_price=as_currency(stop_price if stop_price <bid else bid)\n",
        "  \n",
        "  elif short and not sell:\n",
        "    ask=TDSession.get_quotes([ticker])[ticker.upper()]['askPrice']\n",
        "    instruction='SELL_SHORT'\n",
        "    stop_instruction='BUY_TO_COVER'\n",
        "    stop_price=as_currency(stop_price if stop_price >ask else ask)\n",
        "  \n",
        "  elif not short and sell:\n",
        "    bid=TDSession.get_quotes([ticker])[ticker.upper()]['bidPrice']\n",
        "    instruction='SELL'\n",
        "    stop_instruction='SELL'\n",
        "    stop_price=as_currency(stop_price if stop_price >bid else bid)\n",
        "  \n",
        "  else:\n",
        "    ask=TDSession.get_quotes([ticker])[ticker.upper()]['askPrice']\n",
        "    instruction='BUY_TO_COVER'\n",
        "    stop_instruction='BUY_TO_COVER'\n",
        "    stop_price=as_currency(stop_price if stop_price >ask else ask)\n",
        "    \n",
        "  trigger_order={\n",
        "    \"orderStrategyType\": \"TRIGGER\",\n",
        "    \"session\": \"NORMAL\",\n",
        "    'duration':'DAY',\n",
        "    \"orderType\": \"MARKET\",\n",
        "    \"orderLegCollection\": [\n",
        "      {\n",
        "        \"instruction\": instruction,\n",
        "        \"quantity\": size,\n",
        "        \"instrument\": {\n",
        "          \"assetType\": \"EQUITY\",\n",
        "          \"symbol\": ticker\n",
        "        }\n",
        "      }\n",
        "    ],\n",
        "    \n",
        "    \"childOrderStrategies\": [\n",
        "      {\n",
        " \n",
        "        \"orderStrategyType\": \"SINGLE\",\n",
        "        \"session\": \"NORMAL\",\n",
        "        \"duration\": \"DAY\",\n",
        "        \"orderType\": \"STOP\",\n",
        "        \"stopPrice\": stop_price,\n",
        "        \"orderLegCollection\": [\n",
        "          {\n",
        "            \"instruction\": stop_instruction,\n",
        "            \"quantity\": stop_size,\n",
        "            \"instrument\": {\n",
        "              \"assetType\": \"EQUITY\",\n",
        "              \"symbol\": ticker\n",
        "            }\n",
        "          }\n",
        "        ]\n",
        "      }\n",
        "    ]\n",
        "  }\n",
        " \n",
        "  TDSession.place_order(account_id,trigger_order)\n",
        " \n",
        " \n",
        "def two_trigger_order(ticker,negate_size,size,stop_size,stop_price,TDSession,account_id,short=False):\n",
        "  negate_size=abs(negate_size)\n",
        "  stop_size=abs(stop_size)\n",
        "  size=abs(size)\n",
        "  ticker=ticker.upper()\n",
        " \n",
        "  if not short:\n",
        "    bid=TDSession.get_quotes([ticker])[ticker.upper()]['bidPrice']\n",
        "    instruction='BUY'\n",
        "    stop_instruction='SELL'\n",
        "    negate_instruction='BUY_TO_COVER'\n",
        "    stop_price=as_currency(stop_price if stop_price <bid else bid)\n",
        "    \n",
        "  else:\n",
        "    ask=TDSession.get_quotes([ticker])[ticker.upper()]['askPrice']\n",
        "    instruction='SELL_SHORT'\n",
        "    stop_instruction='BUY_TO_COVER'\n",
        "    negate_instruction='SELL'\n",
        "    stop_price=as_currency(stop_price if stop_price >ask else ask)\n",
        "  \n",
        "  trigger_trigger_order={\n",
        "    \"orderStrategyType\": \"TRIGGER\",\n",
        "    \"session\": \"NORMAL\",\n",
        "    'duration':'DAY',\n",
        "    \"orderType\": \"MARKET\",\n",
        "    \"orderLegCollection\": [\n",
        "      {\n",
        "        \"instruction\": negate_instruction,\n",
        "        \"quantity\": negate_size,\n",
        "        \"instrument\": {\n",
        "          \"assetType\": \"EQUITY\",\n",
        "          \"symbol\": ticker\n",
        "        }\n",
        "      }\n",
        "    ],\n",
        "    \n",
        "    \"childOrderStrategies\": [\n",
        "      {\n",
        "    \"orderStrategyType\": \"TRIGGER\",\n",
        "    \"session\": \"NORMAL\",\n",
        "    'duration':'DAY',\n",
        "    \"orderType\": \"MARKET\",\n",
        "    \"orderLegCollection\": [\n",
        "      {\n",
        "        \"instruction\": instruction,\n",
        "        \"quantity\": size,\n",
        "        \"instrument\": {\n",
        "          \"assetType\": \"EQUITY\",\n",
        "          \"symbol\": ticker\n",
        "        }\n",
        "      }\n",
        "    ],\n",
        "    \n",
        "    \"childOrderStrategies\": [\n",
        "      {\n",
        " \n",
        "        \"orderStrategyType\": \"SINGLE\",\n",
        "        \"session\": \"NORMAL\",\n",
        "        \"duration\": \"DAY\",\n",
        "        \"orderType\": \"STOP\",\n",
        "        \"stopPrice\": stop_price,\n",
        "        \"orderLegCollection\": [\n",
        "          {\n",
        "            \"instruction\": stop_instruction,\n",
        "            \"quantity\": stop_size,\n",
        "            \"instrument\": {\n",
        "              \"assetType\": \"EQUITY\",\n",
        "              \"symbol\": ticker\n",
        "            }\n",
        "          }\n",
        "        ]\n",
        "      }\n",
        "    ]\n",
        "  }\n",
        "    ]\n",
        "  }\n",
        "  \n",
        "  TDSession.place_order(account_id,trigger_trigger_order)\n",
        " \n",
        "def two_trail_order(take_profit,stop_loss,ticker,negate_size,size,stop_size,TDSession,account_id,short=False):\n",
        "  print('two_trail_order')\n",
        "  negate_size=abs(negate_size)\n",
        "  stop_size=abs(stop_size)\n",
        "  take_size=stop_size\n",
        "  size=abs(size)\n",
        "  ticker=ticker.upper()\n",
        "  price=TDSession.get_quotes([ticker.upper()])[ticker.upper()]['lastPrice']\n",
        " \n",
        "  if not short:\n",
        "    \n",
        "    instruction='BUY'\n",
        "    stop_instruction='SELL'\n",
        "    negate_instruction='BUY_TO_COVER'\n",
        "    take_profit+=price\n",
        "    \n",
        "  else:\n",
        "    \n",
        "    instruction='SELL_SHORT'\n",
        "    stop_instruction='BUY_TO_COVER'\n",
        "    negate_instruction='SELL'\n",
        "    take_profit=price-take_profit\n",
        "  \n",
        "  take_instruction=stop_instruction\n",
        "  take_profit=as_currency(take_profit)\n",
        "  \n",
        "  trigger_trigger_order={\n",
        "    \"orderStrategyType\": \"TRIGGER\",\n",
        "    \"session\": \"NORMAL\",\n",
        "    'duration':'DAY',\n",
        "    \"orderType\": \"MARKET\",\n",
        "    \"orderLegCollection\": [\n",
        "      {\n",
        "        \"instruction\": negate_instruction,\n",
        "        \"quantity\": negate_size,\n",
        "        \"instrument\": {\n",
        "          \"assetType\": \"EQUITY\",\n",
        "          \"symbol\": ticker\n",
        "        }\n",
        "      }\n",
        "    ],\n",
        "    \n",
        "    \"childOrderStrategies\": [\n",
        "      {\n",
        "    \"orderStrategyType\": \"TRIGGER\",\n",
        "    \"session\": \"NORMAL\",\n",
        "    'duration':'DAY',\n",
        "    \"orderType\": \"MARKET\",\n",
        "    \"orderLegCollection\": [\n",
        "      {\n",
        "        \"instruction\": instruction,\n",
        "        \"quantity\": size,\n",
        "        \"instrument\": {\n",
        "          \"assetType\": \"EQUITY\",\n",
        "          \"symbol\": ticker\n",
        "        }\n",
        "      }\n",
        "    ],\n",
        "    \n",
        "    \"childOrderStrategies\": [\n",
        "       { \n",
        "      \"orderStrategyType\": \"OCO\",\n",
        "      \"childOrderStrategies\": [\n",
        "        {     \n",
        "          \"orderType\": \"LIMIT\",\n",
        "          \"session\": \"NORMAL\",\n",
        "          \"duration\": \"GOOD_TILL_CANCEL\",\n",
        "          \"price\": take_profit,\n",
        "          'orderStrategyType': 'SINGLE',\n",
        "          \"orderLegCollection\": [\n",
        "            {\n",
        "              \"instruction\": take_instruction,\n",
        "              \"quantity\": take_size,\n",
        "              \"instrument\": {\n",
        "                \"assetType\": \"EQUITY\",\n",
        "                \"symbol\": ticker\n",
        "              }\n",
        "            }\n",
        "          ]\n",
        "        },\n",
        "        {\n",
        "          \n",
        "          \"orderType\": \"TRAILING_STOP\",\n",
        "         \"stopPriceOffset\": stop_loss,\n",
        "         \"stopPriceLinkType\": 'VALUE',\n",
        "         'stopPriceLinkBasis': \"ASK\",\n",
        "         'stopType': 'STANDARD',\n",
        "          \"session\": \"NORMAL\",\n",
        "          \"duration\": \"GOOD_TILL_CANCEL\",\n",
        "          \"orderStrategyType\": \"SINGLE\",\n",
        "          \"orderLegCollection\": [\n",
        "            {\n",
        "              \"instruction\": stop_instruction,\n",
        "              \"quantity\": stop_size,\n",
        "              \"instrument\": {\n",
        "                \"assetType\": \"EQUITY\",\n",
        "                \"symbol\": ticker\n",
        "              }\n",
        "            }\n",
        "          ]\n",
        "        }\n",
        "      ]\n",
        "    }\n",
        "    ]\n",
        "  }\n",
        "    ]\n",
        "  }\n",
        "  \n",
        "  \n",
        "  print(TDSession.place_order(account_id,trigger_trigger_order))\n",
        " \n",
        "def conditional_trail_order(take_profit,stop_loss,ticker,size,stop_size,TDSession,account_id,short=False,sell=False):\n",
        "  \n",
        "  \n",
        "  size=abs(size)\n",
        "  stop_size=abs(stop_size)\n",
        "  take_size=stop_size\n",
        "  ticker=ticker.upper()\n",
        "  price=TDSession.get_quotes([ticker.upper()])[ticker.upper()]['lastPrice']\n",
        " \n",
        "  if not short and not sell:\n",
        "    \n",
        "    instruction='BUY'\n",
        "    stop_instruction='SELL'\n",
        "    take_profit+=price\n",
        "    \n",
        "  \n",
        "  elif short and not sell:\n",
        "    \n",
        "    instruction='SELL_SHORT'\n",
        "    stop_instruction='BUY_TO_COVER'\n",
        "    take_profit=price-take_profit\n",
        "  \n",
        "  elif not short and sell:\n",
        "    \n",
        "    instruction='SELL'\n",
        "    stop_instruction='SELL'\n",
        "    take_profit+=price\n",
        "    \n",
        "  \n",
        "  else:\n",
        "    \n",
        "    instruction='BUY_TO_COVER'\n",
        "    stop_instruction='BUY_TO_COVER'\n",
        "    take_profit=price-take_profit\n",
        "\n",
        "  take_instruction=stop_instruction\n",
        "  take_profit=max(0.01,as_currency(take_profit))\n",
        "  \n",
        "\n",
        "  trigger_order={\n",
        "    \"orderStrategyType\": \"TRIGGER\",\n",
        "    \"session\": \"NORMAL\",\n",
        "    'duration':'DAY',\n",
        "    \"orderType\": \"MARKET\",\n",
        "    \"orderLegCollection\": [\n",
        "      {\n",
        "        \"instruction\": instruction,\n",
        "        \"quantity\": size,\n",
        "        \"instrument\": {\n",
        "          \"assetType\": \"EQUITY\",\n",
        "          \"symbol\": ticker\n",
        "        }\n",
        "      }\n",
        "    ],\n",
        "    \n",
        "    \"childOrderStrategies\": [\n",
        "    {\n",
        "      \n",
        "      \"orderStrategyType\": \"OCO\",\n",
        "      \"childOrderStrategies\": [\n",
        "        {\n",
        "          \n",
        "          \"orderStrategyType\": \"SINGLE\",\n",
        "          \"session\": \"NORMAL\",\n",
        "          \"duration\": \"GOOD_TILL_CANCEL\",\n",
        "          \"orderType\": \"LIMIT\",\n",
        "          \"price\": take_profit,\n",
        "          \"orderLegCollection\": [\n",
        "            {\n",
        "              \"instruction\": take_instruction,\n",
        "              \"quantity\": take_size,\n",
        "              \"instrument\": {\n",
        "                \"assetType\": \"EQUITY\",\n",
        "                \"symbol\": ticker\n",
        "              }\n",
        "            }\n",
        "          ]\n",
        "        },\n",
        "        {\n",
        "          \n",
        "          \"orderType\": \"TRAILING_STOP\",\n",
        "         \"stopPriceOffset\": stop_loss,\n",
        "         \"stopPriceLinkType\": 'VALUE',\n",
        "         'stopPriceLinkBasis': \"ASK\",\n",
        "         'stopType': 'STANDARD',\n",
        "          \"session\": \"NORMAL\",\n",
        "          \"duration\": \"GOOD_TILL_CANCEL\",\n",
        "          \"orderStrategyType\": \"SINGLE\",\n",
        "          \"orderLegCollection\": [\n",
        "            {\n",
        "              \"instruction\": stop_instruction,\n",
        "              \"quantity\": stop_size,\n",
        "              \"instrument\": {\n",
        "                \"assetType\": \"EQUITY\",\n",
        "                \"symbol\": ticker\n",
        "              }\n",
        "            }\n",
        "          ]\n",
        "        }\n",
        "      ]\n",
        "    }\n",
        "  ]\n",
        "}\n",
        " \n",
        "  TDSession.place_order(account_id,trigger_order)\n",
        " \n",
        "def bband(data):\n",
        "  if (data['high'].iloc[-1]>data['hbb'].iloc[-1] and data['close'].iloc[-1]>data['hbb'].iloc[-1]) or (data['low'].iloc[-1]<data['lbb'].iloc[-1] and data['close'].iloc[-1]>data['hbb'].iloc[-1]):\n",
        "    return 1\n",
        "  \n",
        "  elif (data['high'].iloc[-1]>data['hbb'].iloc[-1] and data['close'].iloc[-1]<data['hbb'].iloc[-1]) or (data['low'].iloc[-1]<data['lbb'].iloc[-1] and data['close'].iloc[-1]<data['hbb'].iloc[-1]):\n",
        "    return -1\n",
        "  \n",
        "  else:\n",
        "    return 0\n",
        " \n",
        "def supertrend(data):\n",
        "  data['super']=pandas_ta.supertrend(data['high'],data['low'],data['close'],length=2,multiplier=1).iloc[:,1]\n",
        "  \n",
        "  return data['super'].iloc[-1]/2\n",
        "\n",
        "def momentum(data):\n",
        "  squeeze=squeezed(data)*psar_trend(data)\n",
        "  roc=data['price_roc'].iloc[-5:].mean()\n",
        "  \n",
        "  if (squeeze==1) or (squeeze==-1):\n",
        "    \n",
        "    return scipy.special.expit(roc)\n",
        "  \n",
        "  else:\n",
        "    return 0\n",
        " \n",
        "def mfi2(data):\n",
        "  return -0.5*(data['mfi2'].iloc[-1]>=95)+0.5*(data['mfi2'].iloc[-1]<=5)\n",
        " \n",
        "def rsi2(data):\n",
        "  return -0.5*(data['rsi2'].iloc[-1]>=95)+0.5*(data['rsi2'].iloc[-1]<=5)\n",
        " \n",
        "def cci2(data):\n",
        "  return -0.5*(data['cci2'].iloc[-1]>=65)+0.5*(data['cci2'].iloc[-1]<=-65)\n",
        " \n",
        "def mfi10(data):\n",
        "  if psar_trend(data)==1 and (data['mfi10'].iloc[-1]>=90 or data['mfi10'].iloc[-1]<=40):\n",
        "    return tanm(1-data['mfi10'].iloc[-1]/100)\n",
        "  \n",
        "  elif psar_trend(data)==-1 and (data['mfi10'].iloc[-1]>=60 or data['mfi10'].iloc[-1]<=10):\n",
        "    return tanm(1-data['mfi10'].iloc[-1]/100)\n",
        "  \n",
        "  else:\n",
        "    return 0\n",
        " \n",
        "def rsi10(data):\n",
        "  if psar_trend(data)==1 and (data['rsi10'].iloc[-1]>=80 or data['rsi10'].iloc[-1]<=35):\n",
        "    return tanm(1-data['rsi10'].iloc[-1]/100)\n",
        "  \n",
        "  elif psar_trend(data)==-1 and (data['rsi10'].iloc[-1]>=60 or data['rsi10'].iloc[-1]<=25):\n",
        "    return tanm(1-data['rsi10'].iloc[-1]/100)\n",
        "  \n",
        "  else:\n",
        "    return 0\n",
        " \n",
        "def cci10(data):\n",
        "  if psar_trend(data)==-1 and (data['cci10'].iloc[-1]>=100):\n",
        "    return tanm(1-data['cci10'].iloc[-1]/100)\n",
        "  \n",
        "  elif psar_trend(data)==1 and (data['cci10'].iloc[-1]<=-100):\n",
        "    return tanm(1-data['cci10'].iloc[-1]/100)\n",
        "  \n",
        "  else:\n",
        "    return 0\n",
        " \n",
        "def hma_crossback(data):\n",
        "  if data['close'].iloc[-1]>=data['hma50'].iloc[-1] and data['hma10'].iloc[-1]>=data['hma20'].iloc[-1] and data['hma10'].iloc[-2]<=data['hma20'].iloc[-2]:\n",
        "    return 1\n",
        "  elif data['close'].iloc[-1]<=data['hma50'].iloc[-1] and data['hma10'].iloc[-1]<=data['hma20'].iloc[-1] and data['hma10'].iloc[-2]>=data['hma20'].iloc[-2]:\n",
        "    return -1\n",
        "  else:\n",
        "    return 0\n",
        " \n",
        "def ema_crossback(data):\n",
        "  if data['close'].iloc[-1]>=data['ema50'].iloc[-1] and data['ema10'].iloc[-1]>=data['ema20'].iloc[-1] and data['ema10'].iloc[-2]<=data['ema20'].iloc[-2]:\n",
        "    return 1\n",
        "  elif data['close'].iloc[-1]<=data['ema50'].iloc[-1] and data['ema10'].iloc[-1]<=data['ema20'].iloc[-1] and data['ema10'].iloc[-2]>=data['ema20'].iloc[-2]:\n",
        "    return -1\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "def engulfing(data):\n",
        "  if (data.close.iloc[-2]< data.open.iloc[-2]) & (data.close.iloc[-1] > data.open.iloc[-2]) & (data.open.iloc[-1] < data.close.iloc[-2]):\n",
        "    return 1\n",
        "  elif (data.close.iloc[-2]> data.open.iloc[-2]) & (data.close.iloc[-1] < data.open.iloc[-2]) & (data.open.iloc[-1] > data.close.iloc[-2]):\n",
        "    return -1\n",
        "  else:\n",
        "    return 0\n",
        " \n",
        "def psar_reversal(data):\n",
        "  if data['close'].iloc[-1]>data['psar'].iloc[-1] and data['close'].iloc[-2]<data['psar'].iloc[-2]:\n",
        "    return 1\n",
        "  \n",
        "  elif data['close'].iloc[-1]<data['psar'].iloc[-1] and data['close'].iloc[-2]>data['psar'].iloc[-2]:\n",
        "    return -1\n",
        "    \n",
        "  else:\n",
        "    return 0\n",
        " \n",
        "def squeezed(data):\n",
        "  if data['hbb'].iloc[-1]>data['hkeltner'].iloc[-1] and data['lbb'].iloc[-1]<data['lkeltner'].iloc[-1]:\n",
        "    return 1\n",
        "  \n",
        "  elif data['hbb'].iloc[-1]<data['hkeltner'].iloc[-1] and data['lbb'].iloc[-1]>data['lkeltner'].iloc[-1]:\n",
        "    return -1\n",
        "  \n",
        "  else:\n",
        "    return 0\n",
        " \n",
        "def volume_counter(data):\n",
        "  orig_data=data.copy()\n",
        "  data=data[['volume','vol_ema','close_returns']].iloc[-10:]\n",
        " \n",
        "  data['label']=0\n",
        "  data['label'][data['close_returns']>0]=1\n",
        "  data['label'][data['close_returns']<0]=-1\n",
        " \n",
        "  plus_counter=0\n",
        "  neg_counter=0\n",
        " \n",
        "  for idx in range(len(data)):\n",
        "    if data['label'].iloc[idx]==1 and data['volume'].iloc[idx]>=data['vol_ema'].iloc[idx]:\n",
        "      plus_counter+=1\n",
        "    \n",
        "    elif data['label'].iloc[idx]==-1 and data['volume'].iloc[idx]>=data['vol_ema'].iloc[idx]:\n",
        "      neg_counter+=1\n",
        "    \n",
        "    else:\n",
        "      continue\n",
        " \n",
        "  sum_counter=plus_counter-neg_counter\n",
        "  if (sum_counter>0 and plus_counter>=3) and (psar_trend(orig_data)==1):\n",
        "    \n",
        "    return scipy.special.expit(sum_counter)\n",
        " \n",
        "  elif (sum_counter<0 and neg_counter>=3) and (psar_trend(orig_data)==-1):\n",
        "    return scipy.special.expit(sum_counter)\n",
        " \n",
        "  else:\n",
        "    return 0\n",
        " \n",
        "def dday(data):\n",
        "  window=data.iloc[-75:-50]\n",
        "  counter=0\n",
        "  for i in range(len(window)-1):\n",
        "    if window['close_returns'].iloc[i+1]<=-0.002 and window['volume'].iloc[i+1]>window['volume'].iloc[i]:\n",
        "      counter+=1\n",
        " \n",
        "  return -1*(counter>=4)+0\n",
        "\n",
        "def ichimoku(data):\n",
        " \n",
        "  past,future=pandas_ta.ichimoku(data['high'],data['low'],data['close'])\n",
        "  past.columns=['spanA','spanB','conversion','base','lag']\n",
        "  past=past.drop(['lag'],axis=1)\n",
        "  future.columns=['spanA','spanB']\n",
        " \n",
        "  ichimoku_df=past.append(future)\n",
        " \n",
        "  data=pd.concat([data,ichimoku_df],axis=1)\n",
        "  \n",
        "  data['ichi_score']=0\n",
        " \n",
        "  ichi_up=data['ichi_score'][data['close']>data['conversion']][data['close']>data['base']]\n",
        " \n",
        "  up1=ichi_up[data['close']>data['spanA']][data['spanA']>data['spanB']]+0.5\n",
        " \n",
        "  up2=ichi_up[data['spanA'].shift(-26)>data['spanB'].shift(-26)][data['spanA'].shift(-25)<=data['spanB'].shift(-25)]+0.5#future\n",
        " \n",
        "  ichi_down=data['ichi_score'][data['close']<data['conversion']][data['close']<data['base']]\n",
        " \n",
        "  down1=ichi_down[data['close']<data['spanA']][data['spanA']<data['spanB']]-0.5\n",
        " \n",
        "  down2=ichi_down[data['spanA'].shift(-26)<data['spanB'].shift(-26)][data['spanA'].shift(-25)>=data['spanB'].shift(-25)]-0.5 #future\n",
        " \n",
        "  up3=data['ichi_score'][data['close']>data['spanA']][data['spanA']>data['spanB']][data['close'].shift()<=data['spanA'].shift()]+0.5\n",
        "  down3=data['ichi_score'][data['close']<data['spanA']][data['spanA']<data['spanB']][data['close'].shift()>=data['spanA'].shift()]-0.5\n",
        " \n",
        "  ichi_list=[data['ichi_score'],up1,up2,up3,down1,down2,down3]\n",
        " \n",
        "  ichi_scores=pd.concat(ichi_list,axis=1).sum(1)\n",
        "  \n",
        "  return ichi_scores.iloc[:-26]\n",
        " \n",
        "def psar_trend(data):  \n",
        "  return -1*(data['psar'].iloc[-1]>data['close'].iloc[-1])+1*(data['psar'].iloc[-1]<data['close'].iloc[-1])\n",
        " \n",
        "def necklace(data,momentums=False):  #getting the results for the last day of data\n",
        "  \n",
        "  long_mfi=mfi10(data)/3\n",
        "  long_rsi=rsi10(data)/3\n",
        "  long_cci=cci10(data)/3\n",
        "  \n",
        "  try:\n",
        "    hma_cross=hma_crossback(data)\n",
        "    ema_cross=ema_crossback(data)\n",
        "    \n",
        "  except:\n",
        "    ema_cross=0\n",
        "    hma_cross=0\n",
        "    pass\n",
        "  \n",
        "  psar=psar_reversal(data)\n",
        "  bollinger=bband(data)\n",
        "  \n",
        "  dist=dday(data)\n",
        "  engulf=engulfing(data)\n",
        " \n",
        " \n",
        "  try:\n",
        "    moku=ichimoku(data).iloc[-1]\n",
        "  except:\n",
        "    moku=0\n",
        "    pass\n",
        " \n",
        "  if momentum: \n",
        "    vol_count=volume_counter(data)\n",
        "    score_list=[long_mfi,long_rsi,ema_cross,psar,hma_cross,moku,bollinger,long_cci,vol_count,dist,engulf]\n",
        "  \n",
        "  else:\n",
        "    score_list=[long_mfi,long_rsi,ema_cross,psar,hma_cross,moku,bollinger,long_cci,dist,engulf]\n",
        " \n",
        "  if any(score_list):\n",
        "    aggregate=sum(score_list)  \n",
        "  \n",
        "    short_rsi=rsi2(data)/2\n",
        "    short_mfi=mfi2(data)/3\n",
        "    short_cci=cci2(data)/3\n",
        "    \n",
        "    if momentums:\n",
        "      mom=momentum(data)\n",
        " \n",
        "      tech=[short_rsi,short_mfi,mom,short_cci]\n",
        "    \n",
        "    else:\n",
        "      tech=[short_rsi,short_mfi,short_cci]\n",
        " \n",
        "    aggregate+=sum(tech)\n",
        "  \n",
        "    return aggregate\n",
        "  \n",
        "  else:\n",
        "    return 0\n",
        " \n",
        "def generate_current_views(ticker_list,freq,momentums=False):\n",
        "  data_dict={}\n",
        "  views_series=pd.Series(name='views')\n",
        "  for ticker in ticker_list:\n",
        "    data=yahooTA(ticker,freq)\n",
        "  \n",
        "    data_dict[ticker]=data\n",
        "    weekly=yahooTA(ticker,'1wk')\n",
        "    monthly=yahooTA(ticker,'1mo')\n",
        "    \n",
        "    if momentums:\n",
        "      result=necklace(data,momentums=True)\n",
        "      weekly_result=necklace(weekly,momentums=True)\n",
        "      monthly_result=necklace(monthly,momentums=True)\n",
        "\n",
        "    else:\n",
        "      result=necklace(data)\n",
        "      weekly_result=necklace(weekly)\n",
        "      monthly_result=necklace(monthly)\n",
        "\n",
        "    views_series.loc[ticker]=result+weekly_result/2+monthly_result/3\n",
        " \n",
        "  return dict(views_series[abs(views_series)>0.2]),data_dict\n",
        " \n",
        "def get_current_shares(ticker_list,capital,freq,HRP=False,long_only=False,bl1=False,method='median'):\n",
        "  \n",
        "  _,prime_prices_df=yf_fetch(ticker_list)\n",
        "\n",
        "  if bl1:\n",
        "    views_dict,data_dict=generate_current_views(ticker_list,freq,momentums=True)\n",
        "  else:\n",
        "    views_dict,data_dict=generate_current_views(ticker_list,freq)\n",
        "\n",
        "  views_dict={x:y for x,y in views_dict.items() if y!=0}\n",
        "  \n",
        "  last_prices=prime_prices_df.iloc[-1] \n",
        " \n",
        "  if HRP and not long_only:\n",
        "    neg_dict={x:y for x,y in views_dict.items() if y<0}\n",
        "    pos_dict={x:y for x,y in views_dict.items() if y>0}\n",
        "    pos_weights=HR_Paritize(prime_prices_df,pos_dict,method)\n",
        "    neg_weights=HR_Paritize(prime_prices_df,neg_dict,method)\n",
        "    neg_weights={x:-y for x,y in neg_weights.items()}\n",
        "    comb_weights={**pos_weights,**neg_weights}\n",
        "    weights_df=pd.Series(comb_weights.copy())\n",
        "  \n",
        "  elif HRP and long_only:\n",
        "    views_dict={x:y for x,y in views_dict.items() if y>0}\n",
        "    weights_df=pd.Series(HR_Paritize(prime_prices_df,views_dict,method))\n",
        " \n",
        "  else:\n",
        "    if bl1:\n",
        "      bl_weights=Blacklitter(prime_prices_df[views_dict.keys()],views_dict) \n",
        "    else:\n",
        "      bl_weights=Blacklitter2(prime_prices_df[views_dict.keys()],views_dict,method) #2\n",
        "    weights=bl_weights.copy()\n",
        "    if not HRP and long_only:\n",
        "      weights_df=pd.Series(weights)\n",
        "      if len(weights_df[weights_df>0])>0:\n",
        "        weights_df=weights_df[weights_df>0]\n",
        "    \n",
        "      else:\n",
        "        return weights_df\n",
        "    \n",
        "    else:\n",
        "      weights_df=pd.Series(weights)\n",
        " \n",
        "      \n",
        "  if abs(weights_df).sum()!=1:\n",
        "    corrected_df=weights_df/abs(weights_df).sum() \n",
        "      \n",
        "  else:\n",
        "    corrected_df=weights_df\n",
        " \n",
        "  sign_df=corrected_df/abs(corrected_df)\n",
        "  abs_weights=dict(abs(corrected_df))\n",
        " \n",
        "  sharer=pypfopt.discrete_allocation.DiscreteAllocation(abs_weights,last_prices,capital,0.000001) #0.000001\n",
        " \n",
        "  shares_dict=sharer.greedy_portfolio()[0]\n",
        " \n",
        "  shares_dict={key:shares_dict[key]*sign_df[key] for key in shares_dict}\n",
        " \n",
        "  return shares_dict,data_dict\n",
        " \n",
        "def buy_diff_conditional_order(take_profit,stop_loss,already_dict,shares_dict,ticker,diff_df,sign_df,account_id,TDSession):\n",
        " \n",
        "  conditional_trail_order(take_profit,stop_loss,ticker,abs(diff_df[ticker]),shares_dict[ticker],TDSession,account_id)\n",
        " \n",
        "def sell_diff_conditional_order(take_profit,stop_loss,already_dict,shares_dict,ticker,diff_df,sign_df,account_id,TDSession):\n",
        " \n",
        "  conditional_trail_order(take_profit,stop_loss,ticker,abs(diff_df[ticker]),shares_dict[ticker],TDSession,account_id,sell=True,short=False)\n",
        " \n",
        "def cover_diff_conditional_order(take_profit,stop_loss,already_dict,shares_dict,ticker,diff_df,sign_df,account_id,TDSession):\n",
        " \n",
        "  conditional_trail_order(take_profit,stop_loss,ticker,abs(diff_df[ticker]),shares_dict[ticker],TDSession,account_id,sell=True,short=True)\n",
        " \n",
        "def buy_otota(take_profit,stop_loss,already_dict,shares_dict,ticker,diff_df,sign_df,account_id,TDSession):\n",
        "  \n",
        "  #two_trail_order(take_profit,stop_loss,ticker,already_dict[ticker],shares_dict[ticker],shares_dict[ticker],TDSession,account_id)\n",
        "\n",
        "  conditional_trail_order(take_profit,stop_loss,ticker,shares_dict[ticker],shares_dict[ticker],TDSession,account_id)\n",
        " \n",
        "def short_diff_conditional_order(take_profit,stop_loss,already_dict,shares_dict,ticker,diff_df,sign_df,account_id,TDSession):\n",
        "  \n",
        "  conditional_trail_order(take_profit,stop_loss,ticker,abs(diff_df[ticker]),shares_dict[ticker],TDSession,account_id,short=True,sell=False)\n",
        " \n",
        "def short_otota(take_profit,stop_loss,already_dict,shares_dict,ticker,diff_df,sign_df,account_id,TDSession):\n",
        "  \n",
        "  #two_trail_order(take_profit,stop_loss,ticker,already_dict[ticker],shares_dict[ticker],shares_dict[ticker],TDSession,account_id,short=True)\n",
        "  conditional_trail_order(take_profit,stop_loss,ticker,shares_dict[ticker],shares_dict[ticker],TDSession,account_id,short=True)\n",
        " \n",
        "def buy_conditional_order(take_profit,stop_loss,already_dict,shares_dict,ticker,diff_df,sign_df,account_id,TDSession):\n",
        "  \n",
        "  conditional_trail_order(take_profit,stop_loss,ticker,shares_dict[ticker],shares_dict[ticker],TDSession,account_id)\n",
        " \n",
        "def short_conditional_order(take_profit,stop_loss,already_dict,shares_dict,ticker,diff_df,sign_df,account_id,TDSession):\n",
        "  \n",
        "  conditional_trail_order(take_profit,stop_loss,ticker,shares_dict[ticker],shares_dict[ticker],TDSession,account_id,short=True)\n",
        " \n",
        "def in_already(ticker,already_dict):\n",
        "  return (ticker not in already_dict) *'' +(ticker in already_dict) * 'already'\n",
        "    \n",
        "def shares_sign(ticker,shares_dict):\n",
        "  return (shares_dict[ticker]>0) *'shares>0' + (shares_dict[ticker]<0) * 'shares<0'\n",
        " \n",
        "def sign(ticker,sign_df,diff_df):\n",
        "  \n",
        "  return (ticker not in sign_df)*''+(ticker in sign_df and sign_df[ticker]<0)*'sign<0'+(ticker in sign_df and sign_df[ticker]>0)*'sign>0'\n",
        " \n",
        "def difference(ticker,diff_df,sign_df):\n",
        " \n",
        "  return (ticker not in sign_df or ticker not in diff_df)*''+((ticker in sign_df and ticker in diff_df) and (sign_df[ticker]>0 and diff_df[ticker]>0))*'diff>0'+((ticker in sign_df and ticker in diff_df) and sign_df[ticker]>0 and diff_df[ticker]<0)*'diff<0'\n",
        " \n",
        "def execute_brokerage(ticker_list):\n",
        " \n",
        "  #global account_id,TDSession\n",
        " \n",
        "  TDSession=td_login()\n",
        " \n",
        "  account_id= '270719431'\n",
        "  \n",
        "  position_info=TDSession.get_accounts(account=account_id,fields=['positions'])\n",
        "  order_info=TDSession.get_accounts(account=account_id,fields=['orders'])\n",
        "  balances=order_info['securitiesAccount']['currentBalances']\n",
        "  directional_capital= (balances['buyingPower']+balances['shortBalance']+balances['longMarketValue'])*0.5\n",
        "  long_capital= (balances['buyingPower']+balances['shortBalance']+balances['longMarketValue'])*0.25\n",
        " \n",
        "  #shares_dict,data_dict=get_current_shares(ticker_list,marginal_capital,'1d')\n",
        " \n",
        "  long_shares,data_dict=get_current_shares(ticker_list,long_capital,'1d',long_only=True,HRP=True,bl1=False)\n",
        " \n",
        "  bl_shares,data_dict=get_current_shares(ticker_list,directional_capital,'1d',HRP=True,long_only=False,bl1=False,method='median')\n",
        " \n",
        "  long_df=pd.Series(long_shares)\n",
        "  bl_df=pd.Series(bl_shares)\n",
        " \n",
        "  combined=long_df+bl_df\n",
        " \n",
        "  combined[combined.isnull()]=bl_df\n",
        "  combined[combined.isnull()]=long_df\n",
        " \n",
        "  shares_dict=dict(combined)\n",
        "\n",
        "  print('shares_dict',shares_dict)\n",
        " \n",
        "  cancel_orders(order_info,TDSession,account_id)\n",
        " \n",
        "  already_dict={}\n",
        "    \n",
        "  positions=position_info['securitiesAccount']['positions']\n",
        "  for position in positions:\n",
        "    \n",
        "    ticker=position['instrument']['symbol'].lower() \n",
        "  \n",
        "    size=position['longQuantity'] if position['longQuantity']>position['shortQuantity'] else -position['shortQuantity']\n",
        "    already_dict[ticker]=size\n",
        "  \n",
        "  sign_df=(pd.Series(shares_dict)/pd.Series(already_dict)).dropna()\n",
        "  sign_df=sign_df[sign_df!=1]\n",
        " \n",
        "  bell_off(already_dict,shares_dict,TDSession,account_id,sign_df)\n",
        "  #sell_all(already_dict,TDSession,account_id)\n",
        "  \n",
        "  #except (KeyError):\n",
        "    #pass\n",
        "  \n",
        "  execute_orders(shares_dict,already_dict,data_dict,TDSession,account_id)\n",
        "\n",
        "  TDSession=td_login()\n",
        "  \n",
        "  position_info=TDSession.get_accounts(account=account_id,fields=['positions'])\n",
        "\n",
        "  already_dict={}\n",
        "    \n",
        "  positions=position_info['securitiesAccount']['positions']\n",
        "  for position in positions:\n",
        "    \n",
        "    ticker=position['instrument']['symbol'].lower() \n",
        "  \n",
        "    size=position['longQuantity'] if position['longQuantity']>position['shortQuantity'] else -position['shortQuantity']\n",
        "    already_dict[ticker]=size\n",
        "  \n",
        "  print(set(shares_dict)-set(already_dict))\n",
        "\n",
        "def checkbook(ticker,already_dict,shares_dict,sign_df,diff_df):\n",
        "  return ''.join([in_already(ticker,already_dict),shares_sign(ticker,shares_dict),sign(ticker,sign_df,diff_df),difference(ticker,diff_df,sign_df)])\n",
        " \n",
        "def execute_orders(shares_dict,already_dict,data_dict,TDSession,account_id):\n",
        "  \n",
        "  manual={\n",
        "  'alreadyshares>0sign>0diff>0':buy_diff_conditional_order,\n",
        "  'alreadyshares>0sign>0diff<0':sell_diff_conditional_order,\n",
        "  'alreadyshares>0sign<0': buy_otota,                             \n",
        "  'alreadyshares<0sign>0diff>0': cover_diff_conditional_order,\n",
        "  'alreadyshares<0sign>0diff<0': short_diff_conditional_order,\n",
        "  'alreadyshares<0sign<0': short_otota,\n",
        "  'shares>0': buy_conditional_order,\n",
        "  'shares<0': short_conditional_order\n",
        "  }\n",
        " \n",
        "  sign_df=(pd.Series(shares_dict)/pd.Series(already_dict)).dropna()\n",
        "  sign_df=sign_df[sign_df!=1]\n",
        "  \n",
        "  diff_df=(pd.Series(shares_dict)-pd.Series(already_dict)).dropna()\n",
        "  diff_df=diff_df[(diff_df!=0)]\n",
        " \n",
        "  for ticker in shares_dict:\n",
        "      if ticker in already_dict and ticker not in sign_df:\n",
        "        continue\n",
        "    \n",
        "    #try:\n",
        "      data=data_dict[ticker]\n",
        "\n",
        "      used_data=data[-90:]\n",
        "      used_data.columns=[col.lower() for col in used_data.columns]\n",
        "      pos_data=used_data[used_data['close_returns']>0]\n",
        "      neg_data=used_data[used_data['close_returns']<0]\n",
        "      pos_std=pandas_ta.stdev(pos_data['close'],length=2)\n",
        "      pos_std=norm(pos_std[pos_std<pos_std.quantile(0.95)])\n",
        "      pos_factor=pos_std.std()\n",
        "\n",
        "      std=pandas_ta.stdev(used_data['close'],length=2)\n",
        "      std=norm(std[std<std.quantile(0.95)])\n",
        "      factor=std.std()\n",
        "\n",
        "      neg_std=pandas_ta.stdev(neg_data['close'],length=2)\n",
        "      neg_std=norm(neg_std[neg_std<neg_std.quantile(0.95)])\n",
        "      neg_factor=neg_std.std()\n",
        "\n",
        "      atr=pandas_ta.atr(used_data['high'],used_data['low'],used_data['close'],length=2).dropna()\n",
        "\n",
        "      meany=atr.mean()\n",
        "\n",
        "      y,x,_=plt.hist(atr)\n",
        "\n",
        "      atr= (np.mean(int(x[np.where(y == y.max())][0]))+meany)/2\n",
        "\n",
        "      reg_stop=data['close'].iloc[-1]*0.04\n",
        "\n",
        "      neg_loss=max(0.01,as_currency(min(reg_stop,2.5*atr*neg_factor)))\n",
        "\n",
        "      neg_profit=as_currency(max(0.01,profit_take(neg_std.iloc[-1],neg_loss),profit_takes(neg_std.iloc[-1])))\n",
        "\n",
        "      pos_loss=max(0.01,as_currency(min(reg_stop,2.5*atr*pos_factor)))\n",
        "\n",
        "      pos_profit=as_currency(max(0.01,profit_take(pos_std.iloc[-1],pos_loss),profit_takes(pos_std.iloc[-1])))\n",
        "\n",
        "      if shares_dict[ticker]>0:\n",
        "        take_profit=pos_profit\n",
        "        stop_loss=pos_loss\n",
        "      else:\n",
        "        take_profit=neg_profit\n",
        "        stop_loss=neg_loss\n",
        "\n",
        "      manual[checkbook(ticker,already_dict,shares_dict,sign_df,diff_df)](take_profit,stop_loss,already_dict,shares_dict,ticker,diff_df,sign_df,account_id,TDSession)\n",
        "    \n",
        "    #except Exception as e:\n",
        "      #print(e)\n",
        "      #print(ticker)\n",
        "      #pass\n",
        "    \n",
        "    \n",
        "def cancel_orders(order_info,TDSession,account_id):\n",
        "  filter=['CANCELED','REJECTED','EXPIRED']\n",
        "  \n",
        "  if 'orderStrategies' in order_info['securitiesAccount']:\n",
        "    for order in order_info['securitiesAccount']['orderStrategies']:\n",
        "      if order['status'] in filter:\n",
        "        continue\n",
        "      else:\n",
        "        try:\n",
        "          order_iterator(order,filter,TDSession,account_id)\n",
        "        \n",
        "        except Exception as e:\n",
        "          print(e)\n",
        "          pass\n",
        "\n",
        "def order_iterator(order,filter,TDSession,account_id):\n",
        "  \n",
        "  if ('childOrderStrategies' in order) and (order['status']=='FILLED'):\n",
        "    child_order=order['childOrderStrategies'][0]\n",
        "    while (not child_order['cancelable']) and ('childOrderStrategies' in child_order):\n",
        "      child_order=child_order['childOrderStrategies'][0]\n",
        "\n",
        "    order=child_order\n",
        "    \n",
        "    if order['cancelable']:\n",
        "      try:\n",
        "        TDSession.cancel_order(account_id,order['orderId'])\n",
        "\n",
        "      except Exception as e:\n",
        "        print(e)\n",
        "        pass\n",
        "  \n",
        "  elif order['status'] not in filter and (order['cancelable']):\n",
        "    TDSession.cancel_order(account_id,order['orderId'])\n",
        "    \n",
        "def td_login():\n",
        "    consumer_key='*********************'  \n",
        "    callback_url='*******************'\n",
        "    account_id = '*********'          \n",
        "    client_id=consumer_key\n",
        " \n",
        "    TDSession = TDClient(\n",
        "        client_id=client_id,\n",
        "        redirect_uri=callback_url,\n",
        "        credentials_path=r'C:\\Users\\Michael\\creds.json' \n",
        "    )\n",
        " \n",
        "    print(TDSession.login())\n",
        "    return TDSession\n",
        " \n",
        " \n",
        "def sell_off(already_dict,TDSession,shares_dict,account_id):\n",
        "  for ticker in already_dict:\n",
        "    if ticker not in shares_dict:\n",
        "      #try:\n",
        "        if already_dict[ticker]>0:\n",
        "          sell_order=market_order(ticker,already_dict[ticker],TDSession,account_id,sell=True) #sell all the ones we don't need anymore\n",
        "        elif already_dict[ticker]<0:\n",
        "          sell_order=market_order(ticker,already_dict[ticker],TDSession,account_id,sell=True,short=True)\n",
        "        \n",
        "      #except:\n",
        "        #pass\n",
        " \n",
        "def sell_all(already_dict,TDSession,account_id):\n",
        "  \n",
        "  for ticker in already_dict:\n",
        "    try:\n",
        "      if already_dict[ticker]>0:\n",
        "        #order=market_order(ticker,already_dict[ticker],sell=True)\n",
        "        \n",
        "        order=sell_anytime(ticker,already_dict[ticker],TDSession,account_id)\n",
        "       \n",
        "        \n",
        "      elif already_dict[ticker]<0:\n",
        "        #order=market_order(ticker,already_dict[ticker],sell=True,short=True)\n",
        "       \n",
        "        order=sell_anytime(ticker,already_dict[ticker],TDSession,account_id,short=True)\n",
        "        \n",
        "      #TDSession.place_order(account=account_id,order=order)\n",
        "    except Exception as e:\n",
        "      print(e)\n",
        "      print(ticker)\n",
        "      pass\n",
        " \n",
        "def bell_off(already_dict,shares_dict,TDSession,account_id,diff_df):\n",
        " \n",
        "  diff_set=set(already_dict)-(set(shares_dict))\n",
        " \n",
        "  diff_dict={key:already_dict[key] for key in diff_set}\n",
        " \n",
        "  for ticker in diff_df.index: \n",
        "    if  (ticker in diff_dict and diff_dict[ticker]>0) or (diff_df[ticker]<0 and shares_dict[ticker]<0):\n",
        "      market_order(ticker,already_dict[ticker],TDSession,account_id,sell=True)\n",
        "    elif (ticker in diff_dict and diff_dict[ticker]<0) or (diff_df[ticker]<0 and shares_dict[ticker]>0):\n",
        "      market_order(ticker,already_dict[ticker],TDSession,account_id,sell=True,short=True)\n",
        " \n",
        "def liquid_check(ticker_list):\n",
        "  liquid_list=[]\n",
        "  for ticker in ticker_list:\n",
        "    info=finviz.get_stock(ticker)\n",
        "    \n",
        "    rel_vol=float(info['Rel Volume'])\n",
        "    vol=float(info['Volume'].replace(',',''))\n",
        "    \n",
        "    if rel_vol>=0.65 and vol>1000000:\n",
        "      print(ticker)\n",
        "      liquid_list.append(ticker)\n",
        "  \n",
        "  return liquid_list\n",
        "\n",
        "def profit_take(volatility,stop_loss):\n",
        "  return abs(3.9*volatility-0.1*stop_loss)\n",
        "\n",
        "def cancel_single(ticker):\n",
        "\n",
        "  TDSession=td_login()\n",
        "\n",
        "  account_id= '270719431'\n",
        "\n",
        "  order_info=TDSession.get_accounts(account=account_id,fields=['orders'])\n",
        "\n",
        "  orders=order_info['securitiesAccount']['orderStrategies']\n",
        "\n",
        "  filter=['CANCELED','REJECTED','EXPIRED']\n",
        "\n",
        "  for order in orders:\n",
        "    if (order['orderLegCollection'][0]['instrument']['symbol']==ticker.upper()):\n",
        "      #TDSession.cancel_order(account_id,order['orderId'])\n",
        "\n",
        "      order_iterator(order,filter,TDSession,account_id)\n",
        "\n",
        "def profit_takes(volatility):\n",
        "  return abs(1.007211 - 1.743677/2**(volatility/0.5051997))\n",
        "\n",
        "from time import sleep\n",
        "def brokerage_updater(ticker_list):\n",
        "  \n",
        "    TDSession=td_login()\n",
        "\n",
        "    account_id= '270719431'\n",
        "\n",
        "    position_info=TDSession.get_accounts(account=account_id,fields=['positions'])\n",
        "    order_info=TDSession.get_accounts(account=account_id,fields=['orders'])\n",
        "    balances=order_info['securitiesAccount']['currentBalances']\n",
        "    directional_capital=(balances['buyingPower']+balances['shortBalance']+balances['longMarketValue'])*0.4\n",
        "    long_capital=(balances['buyingPower']+balances['shortBalance']+balances['longMarketValue'])*0.15\n",
        "          \n",
        "    while True:\n",
        "      if dt.datetime.now().time()> dt.time(19,45) and dt.datetime.now().time()< dt.time(19,50):\n",
        "        print('executing brokerage')\n",
        "        execute_brokerage(ticker_list)\n",
        "        break\n",
        "    \n",
        "      long_shares,data_dict=get_current_shares(ticker_list,long_capital,'1d',long_only=True,HRP=True,bl1=False,method='median')\n",
        "\n",
        "      bl_shares,data_dict=get_current_shares(ticker_list,directional_capital,'1d',HRP=True,long_only=False,bl1=False,method='median')\n",
        "\n",
        "      long_df=pd.Series(long_shares)\n",
        "      bl_df=pd.Series(bl_shares)\n",
        "\n",
        "      combined=long_df+bl_df\n",
        "\n",
        "      combined[combined.isnull()]=bl_df\n",
        "      combined[combined.isnull()]=long_df\n",
        "\n",
        "      shares_dict=dict(combined)\n",
        "\n",
        "      TDSession=td_login()\n",
        "\n",
        "      account_id= '270719431'\n",
        "\n",
        "      position_info=TDSession.get_accounts(account=account_id,fields=['positions'])\n",
        "      order_info=TDSession.get_accounts(account=account_id,fields=['orders'])\n",
        "\n",
        "      already_dict={}\n",
        "\n",
        "      positions=position_info['securitiesAccount']['positions']\n",
        "      for position in positions:\n",
        "        \n",
        "        ticker=position['instrument']['symbol'].lower() \n",
        "\n",
        "        size=position['longQuantity'] if position['longQuantity']>position['shortQuantity'] else -position['shortQuantity']\n",
        "        already_dict[ticker]=size\n",
        "\n",
        "      remaining_dict=(set(shares_dict)-set(already_dict))\n",
        "      \n",
        "      for ticker in remaining_dict:\n",
        "        data=yahooTA(ticker,'1d')\n",
        "\n",
        "        used_data=data[-90:]\n",
        "        used_data.columns=[col.lower() for col in used_data.columns]\n",
        "        pos_data=used_data[used_data['close_returns']>0]\n",
        "        neg_data=used_data[used_data['close_returns']<0]\n",
        "        pos_std=pandas_ta.stdev(pos_data['close'],length=2)\n",
        "        pos_std=norm(pos_std[pos_std<pos_std.quantile(0.95)])\n",
        "        pos_factor=pos_std.std()\n",
        "\n",
        "        std=pandas_ta.stdev(used_data['close'],length=2)\n",
        "        std=norm(std[std<std.quantile(0.95)])\n",
        "        factor=std.std()\n",
        "\n",
        "        neg_std=pandas_ta.stdev(neg_data['close'],length=2)\n",
        "        neg_std=norm(neg_std[neg_std<neg_std.quantile(0.95)])\n",
        "        neg_factor=neg_std.std()\n",
        "\n",
        "        atr=pandas_ta.atr(used_data['high'],used_data['low'],used_data['close'],length=2).dropna()\n",
        "\n",
        "        meany=atr.mean()\n",
        "\n",
        "        y,x,_=plt.hist(atr)\n",
        "\n",
        "        atr= (np.mean(int(x[np.where(y == y.max())][0]))+meany)/2\n",
        "\n",
        "        reg_stop=data['close'].iloc[-1]*0.04\n",
        "\n",
        "        neg_loss=max(0.01,as_currency(min(reg_stop,2.5*atr*neg_factor)))\n",
        "\n",
        "        neg_profit=as_currency(max(0.01,profit_take(neg_std.iloc[-1],neg_loss),profit_takes(neg_std.iloc[-1])))\n",
        "\n",
        "        pos_loss=max(0.01,as_currency(min(reg_stop,2.5*atr*pos_factor)))\n",
        "\n",
        "        pos_profit=as_currency(max(0.01,profit_take(pos_std.iloc[-1],pos_loss),profit_takes(pos_std.iloc[-1])))\n",
        "\n",
        "        if shares_dict[ticker]>0:\n",
        "          conditional_trail_order(pos_profit,pos_loss,ticker,shares_dict[ticker],shares_dict[ticker],TDSession,account_id,short=False,sell=False)\n",
        "        \n",
        "        elif shares_dict[ticker]<0:\n",
        "          conditional_trail_order(neg_profit,neg_loss,ticker,shares_dict[ticker],shares_dict[ticker],TDSession,account_id,short=True,sell=False)\n",
        "      sleep(60*9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyhU1EA0Ue_k"
      },
      "source": [
        "ticker_list=['vrtx','calx','aeis','vivo','tpx','acls','amat','mitk','hibb','dell','nx','prg','lh','stc','frd','dks','tpr','lpx','bdsi','agco','exp','pki','tsla','rvlv','goog','leu','msft','xom']\n",
        "\n",
        "#lake,drd,irbt,hear,bgfv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ynibl9yFrrKk"
      },
      "source": [
        "brokerage_updater(ticker_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6G4uUAL5vhwL"
      },
      "source": [
        "execute_brokerage(ticker_list)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
